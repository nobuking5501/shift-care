#!/usr/bin/env python3
"""
ClaudeHelper Session Search Tool
éšœå®³è€…æ–½è¨­å‘ã‘ã‚·ãƒ•ãƒˆç®¡ç†ã‚¢ãƒ—ãƒªé–‹ç™ºå°‚ç”¨ç‰ˆ

Usage:
    python search_session.py --tag "frontend"
    python search_session.py --date "2025-06" --keyword "ã‚·ãƒ•ãƒˆ"
    python search_session.py --keyword "ã‚¨ãƒ©ãƒ¼" --status "completed"
    python search_session.py --recent 10
"""

import os
import json
import argparse
import glob
from datetime import datetime, timedelta
import re
import logging

# Setup logging for better error tracking
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

# Optional fuzzy search support
try:
    from fuzzywuzzy import fuzz, process
    FUZZY_SEARCH_AVAILABLE = True
except ImportError:
    FUZZY_SEARCH_AVAILABLE = False
    logger.warning("fuzzywuzzy not installed. Fuzzy search disabled. Install with: pip install fuzzywuzzy python-Levenshtein")

class SessionSearcher:
    def __init__(self):
        self.base_dir = os.path.dirname(os.path.abspath(__file__))
        self.sessions_dir = os.path.join(self.base_dir, "sessions")
        self.metadata_dir = os.path.join(self.sessions_dir, "metadata")

    def search_sessions(self, tags=None, date_filter=None, keyword=None, status=None, session_type=None, recent=None, fuzzy_search=False, fuzzy_threshold=70):
        """ã‚»ãƒƒã‚·ãƒ§ãƒ³æ¤œç´¢ï¼ˆãƒ•ã‚¡ã‚¸ãƒ¼æ¤œç´¢å¯¾å¿œï¼‰"""
        results = []
        corrupted_files = []
        
        # ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ãƒ•ã‚¡ã‚¤ãƒ«å–å¾—
        metadata_files = glob.glob(os.path.join(self.metadata_dir, "*.json"))
        
        if not metadata_files:
            logger.warning(f"No metadata files found in {self.metadata_dir}")
            return results
        
        logger.info(f"Scanning {len(metadata_files)} metadata files...")
        
        for metadata_file in metadata_files:
            try:
                with open(metadata_file, "r", encoding="utf-8") as f:
                    metadata = json.load(f)
                
                # Validate required fields
                if not self._validate_metadata(metadata):
                    logger.warning(f"Invalid metadata structure: {metadata_file}")
                    continue
                
                # ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°
                if self._matches_filters(metadata, tags, date_filter, keyword, status, session_type, fuzzy_search, fuzzy_threshold):
                    results.append(metadata)
            
            except json.JSONDecodeError as e:
                error_msg = f"JSON decode error in {metadata_file}: {e}"
                logger.error(error_msg)
                corrupted_files.append(metadata_file)
                continue
            except FileNotFoundError as e:
                error_msg = f"File not found: {metadata_file}"
                logger.error(error_msg)
                continue
            except Exception as e:
                error_msg = f"Unexpected error processing {metadata_file}: {e}"
                logger.error(error_msg)
                continue
        
        # Report corrupted files
        if corrupted_files:
            print(f"âš ï¸ {len(corrupted_files)} corrupted metadata files found:")
            for f in corrupted_files:
                print(f"   - {f}")
            print(f"ğŸ’¡ Consider running recovery: python search_session.py --repair")
        
        # ã‚½ãƒ¼ãƒˆï¼ˆæ–°ã—ã„é †ï¼‰
        results.sort(key=lambda x: x.get('timestamp', ''), reverse=True)
        
        # recentåˆ¶é™
        if recent:
            results = results[:recent]
        
        return results

    def _validate_metadata(self, metadata):
        """ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿æ§‹é€ ã®æ¤œè¨¼"""
        required_fields = ['session_id', 'session_name', 'timestamp']
        return all(field in metadata for field in required_fields)

    def _matches_filters(self, metadata, tags, date_filter, keyword, status, session_type, fuzzy_search=False, fuzzy_threshold=70):
        """ãƒ•ã‚£ãƒ«ã‚¿æ¡ä»¶ãƒãƒƒãƒãƒ³ã‚°ï¼ˆãƒ•ã‚¡ã‚¸ãƒ¼æ¤œç´¢å¯¾å¿œï¼‰"""
        # ã‚¿ã‚°ãƒ•ã‚£ãƒ«ã‚¿
        if tags:
            tag_list = [tag.strip() for tag in tags.split(",")]
            if not any(tag in metadata.get('tags', []) for tag in tag_list):
                return False
        
        # æ—¥ä»˜ãƒ•ã‚£ãƒ«ã‚¿
        if date_filter:
            session_date = metadata.get('timestamp', '')
            if date_filter not in session_date:
                return False
        
        # ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ãƒ•ã‚£ãƒ«ã‚¿ï¼ˆãƒ•ã‚¡ã‚¸ãƒ¼æ¤œç´¢å¯¾å¿œï¼‰
        if keyword:
            search_text = f"{metadata.get('session_name', '')} {metadata.get('summary', '')}".lower()
            keyword_lower = keyword.lower()
            
            if fuzzy_search and FUZZY_SEARCH_AVAILABLE:
                # ãƒ•ã‚¡ã‚¸ãƒ¼æ¤œç´¢
                ratio = fuzz.partial_ratio(keyword_lower, search_text)
                if ratio < fuzzy_threshold:
                    return False
            else:
                # é€šå¸¸ã®éƒ¨åˆ†æ–‡å­—åˆ—æ¤œç´¢
                if keyword_lower not in search_text:
                    return False
        
        # ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ãƒ•ã‚£ãƒ«ã‚¿
        if status:
            if metadata.get('status') != status:
                return False
        
        # ã‚¿ã‚¤ãƒ—ãƒ•ã‚£ãƒ«ã‚¿
        if session_type:
            if metadata.get('type') != session_type:
                return False
        
        return True

    def display_results(self, results, show_detail=False):
        """æ¤œç´¢çµæœè¡¨ç¤º"""
        if not results:
            print("ğŸ” æ¤œç´¢çµæœ: è©²å½“ã™ã‚‹ã‚»ãƒƒã‚·ãƒ§ãƒ³ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸ")
            return
        
        print(f"ğŸ” æ¤œç´¢çµæœ: {len(results)}ä»¶ã®ã‚»ãƒƒã‚·ãƒ§ãƒ³ãŒè¦‹ã¤ã‹ã‚Šã¾ã—ãŸ\n")
        
        for i, metadata in enumerate(results, 1):
            timestamp = datetime.fromisoformat(metadata['timestamp']).strftime('%Y/%m/%d %H:%M')
            tags = ', '.join(metadata.get('tags', []))
            status_emoji = "âœ…" if metadata.get('status') == "completed" else "ğŸ”„"
            
            print(f"{i:2d}. {status_emoji} {metadata['session_name']}")
            print(f"    ğŸ“… {timestamp}")
            print(f"    ğŸ·ï¸  {tags}")
            print(f"    ğŸ“ {metadata.get('summary', 'No summary')}")
            
            if show_detail:
                print(f"    ğŸ“ {metadata.get('file_path', 'N/A')}")
                print(f"    ğŸ†” {metadata.get('session_id', 'N/A')}")
            
            print()

    def get_session_content(self, session_id):
        """ã‚»ãƒƒã‚·ãƒ§ãƒ³å†…å®¹å–å¾—"""
        metadata_file = os.path.join(self.metadata_dir, f"{session_id}.json")
        
        try:
            with open(metadata_file, "r", encoding="utf-8") as f:
                metadata = json.load(f)
            
            session_file = metadata.get('file_path')
            if session_file and os.path.exists(session_file):
                with open(session_file, "r", encoding="utf-8") as f:
                    return f.read()
            else:
                return "ã‚»ãƒƒã‚·ãƒ§ãƒ³ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“"
        
        except (json.JSONDecodeError, FileNotFoundError):
            return "ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“"

    def generate_statistics(self, results):
        """çµ±è¨ˆæƒ…å ±ç”Ÿæˆ"""
        if not results:
            return
        
        print("ğŸ“Š çµ±è¨ˆæƒ…å ±")
        print("-" * 40)
        
        # ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹åˆ¥é›†è¨ˆ
        status_count = {}
        type_count = {}
        tag_count = {}
        
        for metadata in results:
            # ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹é›†è¨ˆ
            status = metadata.get('status', 'unknown')
            status_count[status] = status_count.get(status, 0) + 1
            
            # ã‚¿ã‚¤ãƒ—é›†è¨ˆ
            session_type = metadata.get('type', 'unknown')
            type_count[session_type] = type_count.get(session_type, 0) + 1
            
            # ã‚¿ã‚°é›†è¨ˆ
            for tag in metadata.get('tags', []):
                tag_count[tag] = tag_count.get(tag, 0) + 1
        
        print(f"ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹åˆ¥: {dict(status_count)}")
        print(f"ã‚¿ã‚¤ãƒ—åˆ¥: {dict(type_count)}")
        print(f"ã‚ˆãä½¿ã‚ã‚Œã‚‹ã‚¿ã‚°: {dict(sorted(tag_count.items(), key=lambda x: x[1], reverse=True)[:5])}")
        print()

    def repair_corrupted_files(self):
        """ç ´æã—ãŸãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ãƒ•ã‚¡ã‚¤ãƒ«ã®ä¿®å¾©"""
        print("ğŸ”§ ç ´æãƒ•ã‚¡ã‚¤ãƒ«ä¿®å¾©ã‚’é–‹å§‹...")
        metadata_files = glob.glob(os.path.join(self.metadata_dir, "*.json"))
        repaired = 0
        
        for metadata_file in metadata_files:
            try:
                with open(metadata_file, "r", encoding="utf-8") as f:
                    json.load(f)
            except json.JSONDecodeError:
                print(f"ğŸ”§ ä¿®å¾©ä¸­: {metadata_file}")
                backup_path = f"{metadata_file}.backup"
                os.rename(metadata_file, backup_path)
                repaired += 1
        
        print(f"âœ… {repaired}å€‹ã®ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä¿®å¾©ã—ã¾ã—ãŸ")

def main():
    parser = argparse.ArgumentParser(description="ClaudeHelper Session Searcher for Shift-Care App")
    parser.add_argument("--tag", help="ã‚¿ã‚°ã§æ¤œç´¢ï¼ˆã‚«ãƒ³ãƒåŒºåˆ‡ã‚Šã§è¤‡æ•°æŒ‡å®šå¯ï¼‰")
    parser.add_argument("--date", help="æ—¥ä»˜ã§æ¤œç´¢ï¼ˆYYYY-MMå½¢å¼ï¼‰")
    parser.add_argument("--keyword", help="ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã§æ¤œç´¢")
    parser.add_argument("--fuzzy", action="store_true", help="ãƒ•ã‚¡ã‚¸ãƒ¼æ¤œç´¢ã‚’æœ‰åŠ¹åŒ–")
    parser.add_argument("--fuzzy-threshold", type=int, default=70, help="ãƒ•ã‚¡ã‚¸ãƒ¼æ¤œç´¢ã®é–¾å€¤ï¼ˆ0-100ï¼‰")
    parser.add_argument("--status", choices=["completed", "in_progress"], help="ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ã§æ¤œç´¢")
    parser.add_argument("--type", choices=["regular", "checkpoint", "finalize"], help="ã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚¿ã‚¤ãƒ—ã§æ¤œç´¢")
    parser.add_argument("--recent", type=int, help="æœ€æ–°Nä»¶ã‚’è¡¨ç¤º")
    parser.add_argument("--detail", action="store_true", help="è©³ç´°æƒ…å ±ã‚’è¡¨ç¤º")
    parser.add_argument("--stats", action="store_true", help="çµ±è¨ˆæƒ…å ±ã‚’è¡¨ç¤º")
    parser.add_argument("--content", help="æŒ‡å®šã•ã‚ŒãŸSession IDã®å†…å®¹ã‚’è¡¨ç¤º")
    parser.add_argument("--repair", action="store_true", help="ç ´æã—ãŸãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä¿®å¾©")
    
    args = parser.parse_args()
    searcher = SessionSearcher()
    
    # ä¿®å¾©ãƒ¢ãƒ¼ãƒ‰
    if args.repair:
        searcher.repair_corrupted_files()
        return
    
    # ã‚»ãƒƒã‚·ãƒ§ãƒ³å†…å®¹è¡¨ç¤º
    if args.content:
        content = searcher.get_session_content(args.content)
        print(f"ğŸ“„ Session ID: {args.content}")
        print("=" * 50)
        print(content)
        return
    
    # ãƒ•ã‚¡ã‚¸ãƒ¼æ¤œç´¢ã®è­¦å‘Š
    if args.fuzzy and not FUZZY_SEARCH_AVAILABLE:
        print("âš ï¸ ãƒ•ã‚¡ã‚¸ãƒ¼æ¤œç´¢ãŒç„¡åŠ¹ã§ã™ã€‚ä¾å­˜é–¢ä¿‚ã‚’ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã—ã¦ãã ã•ã„:")
        print("pip install fuzzywuzzy python-Levenshtein")
        args.fuzzy = False
    
    # æ¤œç´¢å®Ÿè¡Œ
    results = searcher.search_sessions(
        tags=args.tag,
        date_filter=args.date,
        keyword=args.keyword,
        status=args.status,
        session_type=args.type,
        recent=args.recent,
        fuzzy_search=args.fuzzy,
        fuzzy_threshold=args.fuzzy_threshold
    )
    
    # çµæœè¡¨ç¤º
    searcher.display_results(results, show_detail=args.detail)
    
    # çµ±è¨ˆæƒ…å ±è¡¨ç¤º
    if args.stats:
        searcher.generate_statistics(results)

if __name__ == "__main__":
    main()